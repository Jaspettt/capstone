{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/Question1_Final_CP.xlsx\"\n",
        "xls = pd.ExcelFile(file_path)\n",
        "data = pd.read_excel(xls, sheet_name=\"Лист1\")\n",
        "\n",
        "# Extract the relevant column\n",
        "variable_data = data[\"Variable\"]\n",
        "\n",
        "# Simple Random Sampling (SRS) calculations\n",
        "mean_srs = variable_data.mean()\n",
        "std_dev = variable_data.std(ddof=1)  # Sample standard deviation\n",
        "n = len(variable_data)  # Sample size\n",
        "se_srs = std_dev / np.sqrt(n)\n",
        "\n",
        "t_value = 2.04  # Given t-value for 95% CI\n",
        "ci_lower_srs = mean_srs - t_value * se_srs\n",
        "ci_upper_srs = mean_srs + t_value * se_srs\n",
        "\n",
        "# Round results to 2 decimal places\n",
        "mean_srs = round(mean_srs, 2)\n",
        "se_srs = round(se_srs, 2)\n",
        "ci_lower_srs = round(ci_lower_srs, 2)\n",
        "ci_upper_srs = round(ci_upper_srs, 2)\n",
        "\n",
        "# Stratified Sampling Calculations\n",
        "stratum_counts = data[\"Stratum\"].value_counts().sort_index()\n",
        "total_n = len(data)\n",
        "Wh = (stratum_counts / total_n).round(2).to_dict()\n",
        "\n",
        "stratum_means = data.groupby(\"Stratum\")[\"Variable\"].mean()\n",
        "mean_stratified = np.sum(pd.Series(Wh) * stratum_means)\n",
        "\n",
        "stratum_vars = data.groupby(\"Stratum\")[\"Variable\"].var(ddof=1)\n",
        "stratum_ns = data.groupby(\"Stratum\")[\"Variable\"].count()\n",
        "\n",
        "se_stratified = np.sqrt(np.sum((pd.Series(Wh)**2) * (stratum_vars / stratum_ns)))\n",
        "\n",
        "d_value = se_stratified / se_srs\n",
        "d_squared = d_value ** 2\n",
        "Neff = total_n / d_squared\n",
        "\n",
        "# Round results to 2 decimal places\n",
        "mean_stratified = round(mean_stratified, 2)\n",
        "se_stratified = round(se_stratified, 2)\n",
        "d_value = round(d_value, 2)\n",
        "d_squared = round(d_squared, 2)\n",
        "Neff = round(Neff, 2)\n",
        "\n",
        "# Print results\n",
        "print(\"Simple Random Sampling (SRS) Results:\")\n",
        "print(f\"Mean (SRS): {mean_srs}\")\n",
        "print(f\"Standard Error (SRS): {se_srs}\")\n",
        "print(f\"95% Confidence Interval (SRS): ({ci_lower_srs}, {ci_upper_srs})\\n\")\n",
        "\n",
        "print(\"Stratified Random Sampling (Stratified RS) Results:\")\n",
        "print(f\"Stratum Weights (Wh): {Wh}\")\n",
        "print(f\"Mean (Stratified RS): {mean_stratified}\")\n",
        "print(f\"Standard Error (Stratified RS): {se_stratified}\")\n",
        "print(f\"d-value (SE_stratified / SE_SRS): {d_value}\")\n",
        "print(f\"d-squared: {d_squared}\")\n",
        "print(f\"Neff (Effective Sample Size): {Neff}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "naaxV2aBz6yH",
        "outputId": "e301c40c-2d5f-4cd6-8481-f7891915329f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Cluster'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Cluster'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a63ecca79b26>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Stratified Sampling Calculations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mstratum_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Cluster\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtotal_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mWh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstratum_counts\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Cluster'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Load the new dataset from CSV\n",
        "file_path_csv = \"/content/Question2_Dataset.csv\"\n",
        "\n",
        "# Read the CSV file\n",
        "df_new = pd.read_csv(file_path_csv)\n",
        "\n",
        "# Display the first few rows to inspect its structure\n",
        "df_new.head()\n",
        "# Extract features and target\n",
        "X = df_new.iloc[:, :-1].values  # Features: X1, X2, X3, X4\n",
        "y = df_new.iloc[:, -1].values   # Target: Y\n",
        "m = len(y)  # Number of training examples\n",
        "\n",
        "# Normalize features: Z = (x - mean) / std\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X_norm = (X - X_mean) / X_std\n",
        "\n",
        "# Add intercept term (column of ones) to X\n",
        "X_norm = np.c_[np.ones(m), X_norm]  # Shape: (m, 5), with first column = 1\n",
        "\n",
        "# Function to perform gradient descent\n",
        "def gradient_descent(X, y, theta, alpha, num_iters):\n",
        "    m = len(y)\n",
        "    J_history = []\n",
        "\n",
        "    for _ in range(num_iters):\n",
        "        gradient = (1 / m) * X.T @ (X @ theta - y)  # Compute gradient\n",
        "        theta -= alpha * gradient  # Update theta\n",
        "        cost = (1 / (2 * m)) * np.sum((X @ theta - y) ** 2)  # Compute cost\n",
        "        J_history.append(cost)\n",
        "\n",
        "    return theta, J_history\n",
        "\n",
        "# Set hyperparameters\n",
        "alpha = 0.1  # Learning rate\n",
        "iterations_list = [10, 100, 1000]  # Iterations to evaluate\n",
        "\n",
        "# Run gradient descent for different iterations\n",
        "results = []\n",
        "for n in iterations_list:\n",
        "    theta_opt, cost_history = gradient_descent(X_norm, y, np.zeros(X_norm.shape[1]), alpha, n)\n",
        "    max_theta = round(np.max(theta_opt), 2)  # Maximum theta value\n",
        "    cost_rounded = round(cost_history[-1])  # Rounded cost function value\n",
        "    results.append((n, cost_rounded, max_theta))\n",
        "\n",
        "# Display results\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRUsOKwJ6Tqg",
        "outputId": "d5c0e5e8-4bdd-4b3b-9e77-90dd20758c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(10, 31, 12.08), (100, 2, 18.54), (1000, 2, 18.54)]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Given confusion matrix values\n",
        "TP = 200  # True Positives (Actual Cat, Predicted Cat)\n",
        "FN = 300  # False Negatives (Actual Cat, Predicted Not Cat)\n",
        "FP = 120  # False Positives (Actual Not Cat, Predicted Cat)\n",
        "TN = 180  # True Negatives (Actual Not Cat, Predicted Not Cat)\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "\n",
        "# Calculate Precision\n",
        "precision = TP / (TP + FP)\n",
        "\n",
        "# Calculate Recall\n",
        "recall = TP / (TP + FN)\n",
        "\n",
        "# Calculate F1-Score\n",
        "f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Round results to 3 decimal places\n",
        "accuracy = round(accuracy, 3)\n",
        "precision = round(precision, 3)\n",
        "recall = round(recall, 3)\n",
        "f1_score = round(f1_score, 3)\n",
        "\n",
        "(accuracy, precision, recall, f1_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxozfqwo86Us",
        "outputId": "fc481eaf-6cf0-4a6f-e0ad-e7e5e81269ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.475, 0.625, 0.4, 0.488)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}